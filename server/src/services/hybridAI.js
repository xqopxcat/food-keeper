import { identifyFoodItems as identifyOpenAI, extractTextFromImage as ocrOpenAI } from './aiRecognition.js';
import { identifyFoodItemsGoogle, extractTextFromImageGoogle } from './googleVisionAI.js';

/**
 * æ™ºèƒ½ AI è·¯ç”±æœå‹™ - æ ¹æ“šæƒ…æ³é¸æ“‡æœ€ä½³çš„ AI æœå‹™
 */

/**
 * æ··åˆ AI è­˜åˆ¥ç­–ç•¥ - ç›®å‰å°ˆæ³¨ä½¿ç”¨ Google Vision API
 * @param {string} imageBase64 - Base64 ç·¨ç¢¼çš„åœ–ç‰‡  
 * @param {object} options - è­˜åˆ¥é¸é …
 * @returns {Promise<object>} è­˜åˆ¥çµæœ
 */
export async function hybridFoodIdentification(imageBase64, options = {}) {
  const {
    strategy = 'google', // é è¨­ä½¿ç”¨ Google Vision API
    preferSpeed = true,  // Google Vision é€Ÿåº¦è¼ƒå¿«
    preferAccuracy = true,
    language = 'zh-TW'
  } = options;

  console.log(`ğŸ¤– ä½¿ç”¨æ··åˆ AI è­˜åˆ¥ç­–ç•¥: ${strategy} (é è¨­: Google Vision)`);

  try {
    switch (strategy) {
      case 'openai':
        console.log('âš ï¸  OpenAI ç­–ç•¥å·²æš«åœï¼Œè‡ªå‹•åˆ‡æ›åˆ° Google Vision');
        return await identifyWithGoogle(imageBase64, options);
        
      case 'google':
        return await identifyWithGoogle(imageBase64, options);
        
      case 'both':
        console.log('âš ï¸  æ··åˆç­–ç•¥å·²æš«åœï¼Œä½¿ç”¨ Google Vision');
        return await identifyWithGoogle(imageBase64, options);
        
      case 'auto':
      default:
        return await autoSelectStrategy(imageBase64, options);
    }
  } catch (error) {
    console.error('Hybrid AI identification error:', error);
    return {
      success: false,
      error: error.message || 'æ··åˆ AI è­˜åˆ¥å¤±æ•—',
      items: [],
      totalItems: 0,
      strategy: 'google'
    };
  }
}

/**
 * è‡ªå‹•é¸æ“‡æœ€ä½³ç­–ç•¥ - ç•¶å‰å°ˆæ³¨ä½¿ç”¨ Google Vision API
 */
async function autoSelectStrategy(imageBase64, options) {
  const { preferSpeed, preferAccuracy, language } = options;
  
  // æª¢æŸ¥ API å¯ç”¨æ€§
  const openaiAvailable = !!process.env.OPENAI_API_KEY;
  const googleAvailable = !!process.env.GOOGLE_CLOUD_PROJECT_ID && !!process.env.GOOGLE_APPLICATION_CREDENTIALS;
  
  if (!googleAvailable && !openaiAvailable) {
    throw new Error('æ²’æœ‰å¯ç”¨çš„ AI æœå‹™ï¼Œè«‹è¨­å®š Google Vision API æˆ– OpenAI API');
  }

  // å„ªå…ˆä½¿ç”¨ Google Vision API
  if (googleAvailable) {
    console.log('ğŸ¯ è‡ªå‹•é¸æ“‡: Google Vision API (ç•¶å‰ä¸»è¦æœå‹™)');
    return await identifyWithGoogle(imageBase64, options);
  }

  // Google Vision ä¸å¯ç”¨æ™‚çš„å‚™æ´æ–¹æ¡ˆ
  if (openaiAvailable) {
    console.log('âš ï¸  Google Vision ä¸å¯ç”¨ï¼Œä½¿ç”¨ OpenAI ä½œç‚ºå‚™æ´');
    return await identifyWithOpenAI(imageBase64, options);
  }
  
  throw new Error('æ‰€æœ‰ AI æœå‹™éƒ½ä¸å¯ç”¨');
}

/**
 * ä½¿ç”¨ OpenAI è­˜åˆ¥
 */
async function identifyWithOpenAI(imageBase64, options) {
  const startTime = Date.now();
  const result = await identifyOpenAI(imageBase64, options);
  const processingTime = Date.now() - startTime;
  
  return {
    ...result,
    strategy: 'openai',
    processingTime: processingTime
  };
}

/**
 * ä½¿ç”¨ Google Vision è­˜åˆ¥
 */
async function identifyWithGoogle(imageBase64, options) {
  const startTime = Date.now();
  const result = await identifyFoodItemsGoogle(imageBase64, options);
  const processingTime = Date.now() - startTime;
  
  return {
    ...result,
    strategy: 'google',
    processingTime: processingTime
  };
}

/**
 * åŒæ™‚ä½¿ç”¨å…©å€‹ API ä¸¦åˆä½µçµæœ
 */
async function identifyWithBoth(imageBase64, options) {
  const startTime = Date.now();
  
  console.log('ğŸ”„ ä¸¦è¡Œä½¿ç”¨ OpenAI å’Œ Google Vision');
  
  const [openaiResult, googleResult] = await Promise.allSettled([
    identifyOpenAI(imageBase64, options).catch(e => ({ success: false, error: e.message, items: [] })),
    identifyFoodItemsGoogle(imageBase64, options).catch(e => ({ success: false, error: e.message, items: [] }))
  ]);
  
  const processingTime = Date.now() - startTime;
  
  // åˆä½µçµæœ
  const mergedResult = mergeIdentificationResults(
    openaiResult.status === 'fulfilled' ? openaiResult.value : { success: false, items: [] },
    googleResult.status === 'fulfilled' ? googleResult.value : { success: false, items: [] }
  );
  
  return {
    ...mergedResult,
    strategy: 'both',
    processingTime: processingTime,
    individual_results: {
      openai: openaiResult.status === 'fulfilled' ? openaiResult.value : null,
      google: googleResult.status === 'fulfilled' ? googleResult.value : null
    }
  };
}

/**
 * åˆä½µå…©å€‹ AI çš„è­˜åˆ¥çµæœ
 */
function mergeIdentificationResults(openaiResult, googleResult) {
  const mergedItems = [];
  const seenItemKeys = new Set();
  
  // å„ªå…ˆä½¿ç”¨ OpenAI çµæœ (é€šå¸¸æ›´æº–ç¢º)
  if (openaiResult.success && openaiResult.items) {
    openaiResult.items.forEach(item => {
      mergedItems.push({
        ...item,
        sources: ['openai']
      });
      if (item.itemKey) seenItemKeys.add(item.itemKey);
    });
  }
  
  // æ·»åŠ  Google Vision çš„è£œå……çµæœ
  if (googleResult.success && googleResult.items) {
    googleResult.items.forEach(item => {
      if (!item.itemKey || !seenItemKeys.has(item.itemKey)) {
        mergedItems.push({
          ...item,
          sources: ['google'],
          confidence: item.confidence * 0.9 // ç¨å¾®é™ä½æ¬Šé‡
        });
        if (item.itemKey) seenItemKeys.add(item.itemKey);
      } else {
        // å¦‚æœåŒæ¨£çš„é£Ÿæè¢«å…©å€‹ AI è­˜åˆ¥åˆ°ï¼Œå¢åŠ ä¿¡å¿ƒåº¦
        const existingItem = mergedItems.find(existing => existing.itemKey === item.itemKey);
        if (existingItem) {
          existingItem.sources.push('google');
          existingItem.confidence = Math.min(1, existingItem.confidence + 0.1);
          existingItem.notes += ` (Google Vision ç¢ºèª)`;
        }
      }
    });
  }
  
  // æŒ‰ä¿¡å¿ƒåº¦æ’åº
  mergedItems.sort((a, b) => b.confidence - a.confidence);
  
  return {
    success: mergedItems.length > 0,
    items: mergedItems,
    totalItems: mergedItems.length,
    aiProvider: 'hybrid',
    merge_strategy: 'confidence_weighted'
  };
}

/**
 * æ··åˆ OCR æ–‡å­—è­˜åˆ¥ - ç•¶å‰å°ˆæ³¨ä½¿ç”¨ Google Vision API
 */
export async function hybridTextExtraction(imageBase64, options = {}) {
  const { strategy = 'google' } = options; // é è¨­ä½¿ç”¨ Google Vision
  
  console.log(`ğŸ“ ä½¿ç”¨æ··åˆ OCR ç­–ç•¥: ${strategy} (é è¨­: Google Vision)`);
  
  try {
    switch (strategy) {
      case 'openai':
        console.log('âš ï¸  OpenAI OCR å·²æš«åœï¼Œè‡ªå‹•åˆ‡æ›åˆ° Google Vision');
        return await ocrWithGoogle(imageBase64, options);
        
      case 'google':
        return await ocrWithGoogle(imageBase64, options);
        
      case 'both':
        console.log('âš ï¸  æ··åˆ OCR å·²æš«åœï¼Œä½¿ç”¨ Google Vision');
        return await ocrWithGoogle(imageBase64, options);
        
      case 'auto':
      default:
        return await autoSelectOCRStrategy(imageBase64, options);
    }
  } catch (error) {
    console.error('Hybrid OCR error:', error);
    return {
      success: false,
      error: error.message || 'æ··åˆ OCR è­˜åˆ¥å¤±æ•—',
      text: {},
      strategy: 'google'
    };
  }
}

/**
 * è‡ªå‹•é¸æ“‡ OCR ç­–ç•¥ - å°ˆæ³¨ä½¿ç”¨ Google Vision API
 */
async function autoSelectOCRStrategy(imageBase64, options) {
  const googleAvailable = !!process.env.GOOGLE_CLOUD_PROJECT_ID && !!process.env.GOOGLE_APPLICATION_CREDENTIALS;
  const openaiAvailable = !!process.env.OPENAI_API_KEY;
  
  // å„ªå…ˆä½¿ç”¨ Google Vision OCR (OCR æ€§èƒ½å„ªç§€)
  if (googleAvailable) {
    console.log('ğŸ“„ ä½¿ç”¨ Google Vision OCR (ç•¶å‰ä¸»è¦æœå‹™)');
    return await ocrWithGoogle(imageBase64, options);
  }
  
  // Google Vision ä¸å¯ç”¨æ™‚çš„å‚™æ´æ–¹æ¡ˆ
  if (openaiAvailable) {
    console.log('âš ï¸  Google Vision ä¸å¯ç”¨ï¼Œä½¿ç”¨ OpenAI OCR ä½œç‚ºå‚™æ´');
    return await ocrWithOpenAI(imageBase64, options);
  }
  
  return { 
    success: false, 
    error: 'æ²’æœ‰å¯ç”¨çš„ OCR æœå‹™ï¼Œè«‹è¨­å®š Google Vision API', 
    text: {},
    strategy: 'google'
  };
}
}

/**
 * OpenAI OCR
 */
async function ocrWithOpenAI(imageBase64, options) {
  const startTime = Date.now();
  const result = await ocrOpenAI(imageBase64);
  const processingTime = Date.now() - startTime;
  
  return {
    ...result,
    strategy: 'openai',
    processingTime: processingTime
  };
}

/**
 * Google Vision OCR
 */
async function ocrWithGoogle(imageBase64, options) {
  const startTime = Date.now();
  const result = await extractTextFromImageGoogle(imageBase64);
  const processingTime = Date.now() - startTime;
  
  return {
    ...result,
    strategy: 'google',
    processingTime: processingTime
  };
}

/**
 * åŒæ™‚ä½¿ç”¨å…©å€‹ OCR ä¸¦åˆä½µçµæœ
 */
async function ocrWithBoth(imageBase64, options) {
  const startTime = Date.now();
  
  console.log('ğŸ“„ ä¸¦è¡Œä½¿ç”¨ OpenAI å’Œ Google Vision OCR');
  
  const [openaiResult, googleResult] = await Promise.allSettled([
    ocrOpenAI(imageBase64).catch(e => ({ success: false, error: e.message, text: {} })),
    extractTextFromImageGoogle(imageBase64).catch(e => ({ success: false, error: e.message, text: {} }))
  ]);
  
  const processingTime = Date.now() - startTime;
  
  // åˆä½µ OCR çµæœ
  const mergedText = mergeOCRResults(
    openaiResult.status === 'fulfilled' ? openaiResult.value : { success: false, text: {} },
    googleResult.status === 'fulfilled' ? googleResult.value : { success: false, text: {} }
  );
  
  return {
    success: Object.keys(mergedText).length > 0,
    text: mergedText,
    strategy: 'both',
    processingTime: processingTime,
    individual_results: {
      openai: openaiResult.status === 'fulfilled' ? openaiResult.value : null,
      google: googleResult.status === 'fulfilled' ? googleResult.value : null
    }
  };
}

/**
 * åˆä½µ OCR çµæœ
 */
function mergeOCRResults(openaiResult, googleResult) {
  const merged = {};
  
  // å„ªå…ˆä½¿ç”¨çµæ§‹åŒ–ç¨‹åº¦æ›´é«˜çš„çµæœ
  if (openaiResult.success && openaiResult.text) {
    Object.assign(merged, openaiResult.text);
  }
  
  // è£œå…… Google çš„çµæœ
  if (googleResult.success && googleResult.text) {
    Object.keys(googleResult.text).forEach(key => {
      if (!merged[key] || merged[key] === null) {
        merged[key] = googleResult.text[key];
      }
    });
  }
  
  return merged;
}

/**
 * å–å¾—å¯ç”¨çš„ AI æœå‹™ç‹€æ…‹ - ç•¶å‰å°ˆæ³¨ä½¿ç”¨ Google Vision
 */
export function getHybridAIStatus() {
  const googleAvailable = !!process.env.GOOGLE_CLOUD_PROJECT_ID && !!process.env.GOOGLE_APPLICATION_CREDENTIALS;
  const openaiAvailable = !!process.env.OPENAI_API_KEY;
  
  const status = {
    current: {
      primary: 'google',
      fallback: openaiAvailable ? 'openai' : null,
      description: 'ç•¶å‰å°ˆæ³¨ä½¿ç”¨ Google Vision APIï¼ŒOpenAI ä½œç‚ºå‚™æ´'
    },
    google: {
      available: googleAvailable,
      active: true,
      capabilities: ['object-detection', 'label-detection', 'ocr', 'fast-processing'],
      benefits: ['æ¯æœˆ1000æ¬¡å…è²»', 'å¿«é€Ÿå›æ‡‰', 'OCRæ€§èƒ½å„ªç§€']
    },
    openai: {
      available: openaiAvailable,
      active: false, // æš«æ™‚åœç”¨ä½œç‚ºä¸»è¦æœå‹™
      model: process.env.OPENAI_MODEL || 'gpt-4o-mini',
      capabilities: ['food-identification', 'ocr', 'contextual-understanding', 'multilingual'],
      benefits: ['é«˜æº–ç¢ºåº¦', 'å°ç£é£Ÿæç†è§£ä½³', 'è¤‡é›œå ´æ™¯è­˜åˆ¥'],
      note: 'ä¿ç•™ä½œç‚ºå‚™æ´æœå‹™ï¼Œæœªä¾†å¯é‡æ–°å•Ÿç”¨'
    },
    hybrid: {
      enabled: true,
      defaultStrategy: 'google',
      availableStrategies: ['auto', 'google'],
      recommended: 'google',
      fallbackStrategy: openaiAvailable ? 'openai' : 'google-only'
    },
    recommendations: {
      setup: googleAvailable ? 
        'âœ… Google Vision å·²è¨­å®šï¼Œå¯é–‹å§‹ä½¿ç”¨' : 
        'âš ï¸ è«‹è¨­å®š Google Vision API ä»¥ä½¿ç”¨ AI è­˜åˆ¥åŠŸèƒ½',
      usage: 'Google Vision API æä¾›æ¯æœˆ1000æ¬¡å…è²»é¡åº¦ï¼Œé©åˆå¤§å¤šæ•¸ä½¿ç”¨å ´æ™¯'
    }
  };
  
  return status;
}